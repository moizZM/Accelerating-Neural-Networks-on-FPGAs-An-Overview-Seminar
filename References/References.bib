@article{FPGA_Review_DeepLearning_2020,
  author = {Ibrahim, Asmaa and Attia, Ashraf and Hussein, Nayera},
  title = {FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review},
  journal = {IEEE Access},
  volume = {8},
  pages = {134824--134849},
  year = {2020},
  doi = {10.1109/ACCESS.2020.3009390},
  NOTE = {used its abstract to write the introduction }
}
@inproceedings{Survey_FPGA_ML_2021,
  author = {H. Ali and M. D. Samad and M. S. Hossain and G. Muhammad},
  title = {A Survey on FPGA-Based Accelerator for Machine Learning},
  booktitle = {2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)},
  pages = {145--150},
  year = {2021},
  publisher = {IEEE},
  doi = {10.1109/ICAIIC51459.2021.9415204}
}
@inproceedings{SCNN_Accelerator_2017,
  author = {A. Parashar and M. Rhu and A. Mukkara and A. Puglielli and R. Venkatesan and B. Khailany and J. Emer and S. W. Keckler and W. J. Dally},
  title = {SCNN: An Accelerator for Compressed-Sparse Convolutional Neural Networks},
  booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture (ISCA)},
  pages = {27--40},
  year = {2017},
  publisher = {ACM},
  doi = {10.1145/3079856.3080254}
}
-----------------------------------------------------------------------
% used for writing the intro of my report all these refrances are taken from FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review

@article{Russakovsky2015_ImageNet,
  author = {O. Russakovsky and others},
  title = {ImageNet Large Scale Visual Recognition Challenge},
  journal = {International Journal of Computer Vision},
  volume = {115},
  number = {3},
  pages = {211--252},
  year = {2015},
  doi = {10.1007/s11263-015-0816-y},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} 
}
@inproceedings{Nomura2007_ProjectionCNN,
  author = {O. Nomura and T. Morie},
  title = {Projection-field-type VLSI convolutional neural networks using merged/mixed analog-digital approach},
  booktitle = {Proceedings of the International Conference on Neural Information Processing},
  pages = {1081--1090},
  year = {2007},
  publisher = {Springer},
  address = {Berlin, Germany},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} 
}
@inproceedings{Chilimbi2014_ProjectAdam,
  author = {T. M. Chilimbi and Y. Suzue and J. Apacible and K. Kalyanaraman},
  title = {Project Adam: Building an efficient and scalable deep learning training system},
  booktitle = {Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
  volume = {14},
  pages = {571--582},
  year = {2014},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@inproceedings{Yazdanbakhsh2015_NeuralAcceleration,
  author = {A. Yazdanbakhsh and J. Park and H. Sharma and P. Lot-Kamran and H. Esmaeilzadeh},
  title = {Neural acceleration for GPU throughput processors},
  booktitle = {Proceedings of the 48th International Symposium on Microarchitecture (MICRO)},
  pages = {482--493},
  year = {2015},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@article{Hinton2012_AcousticModeling,
  author = {G. Hinton and others},
  title = {Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups},
  journal = {IEEE Signal Processing Magazine},
  volume = {29},
  number = {6},
  pages = {82--97},
  year = {2012},
  doi = {10.1109/MSP.2012.2205597},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@inproceedings{Vasudevan2017_ParallelConv,
  author = {A. Vasudevan and A. Anderson and D. Gregg},
  title = {Parallel multi-channel convolution using general matrix multiplication},
  booktitle = {2017 IEEE 28th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
  pages = {19--24},
  year = {2017},
  doi = {10.1109/ASAP.2017.7995251},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@article{Guo2018_AngelEye,
  author = {K. Guo and others},
  title = {Angel-Eye: A Complete Design Flow for Mapping CNN onto Embedded FPGA},
  journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume = {37},
  number = {1},
  pages = {35--47},
  year = {2018},
  doi = {10.1109/TCAD.2017.2760518},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@article{Misra2010_ANNinHardware,
  author = {J. Misra and I. Saha},
  title = {Artificial Neural Networks in Hardware: A Survey of Two Decades of Progress},
  journal = {Neurocomputing},
  volume = {74},
  number = {1--3},
  pages = {239--255},
  year = {2010},
  doi = {10.1016/j.neucom.2010.03.021},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@inproceedings{Esmaeilzadeh2012_NeuralApprox,
  author = {H. Esmaeilzadeh and A. Sampson and L. Ceze and D. Burger},
  title = {Neural acceleration for general-purpose approximate programs},
  booktitle = {45th Annual IEEE/ACM International Symposium on Microarchitecture},
  pages = {449--460},
  year = {2012},
  doi = {10.1109/MICRO.2012.52},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@inproceedings{Han2016_EIE,
  author = {S. Han and others},
  title = {EIE: Efficient Inference Engine on Compressed Deep Neural Network},
  booktitle = {43rd Annual International Symposium on Computer Architecture (ISCA)},
  pages = {243--254},
  year = {2016},
  doi = {10.1109/ISCA.2016.30},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@article{Du2018_ReconfigurableCNN,
  author = {L. Du and others},
  title = {A Reconfigurable Streaming Deep Convolutional Neural Network Accelerator for Internet of Things},
  journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  volume = {65},
  number = {1},
  pages = {198--208},
  year = {2018},
  doi = {10.1109/TCSI.2017.2705055},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} }
@book{Vanderbauwhede2013_HPCFPGAs,
  author = {W. Vanderbauwhede and K. Benkrid},
  title = {High-Performance Computing Using FPGAs},
  publisher = {Springer},
  address = {New York, NY, USA},
  year = {2013},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} 
}
@article{Putnam2014_ReconfigurableFabric,
  author = {A. Putnam and others},
  title = {A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services},
  journal = {ACM SIGARCH Computer Architecture News},
  volume = {42},
  number = {3},
  pages = {13--24},
  year = {2014},
  doi = {10.1145/2678373.2665678},
   NOTE = {taken from  FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review} 
}
---
% for FPGA part i used the follwoing refrances from the report FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review

@article{Villasenor1997_ConfigurableComputing,
  author = {J. Villasenor and W. H. Mangione-Smith},
  title = {Configurable Computing},
  journal = {Scientific American},
  volume = {276},
  number = {6},
  pages = {66--71},
  year = {1997}
}
@article{Herbordt2008_FPGAComputingModels,
  author = {M. C. Herbordt and Y. Gu and T. VanCourt and J. Model and B. Sukhwani and M. Chiu},
  title = {Computing Models for FPGA-Based Accelerators},
  journal = {Computer Science and Engineering},
  volume = {10},
  number = {6},
  pages = {35--45},
  year = {2008},
  month = {Nov.}
}
@book{Varma2016_FPGABioinfo,
  author = {B. S. C. Varma and K. Paul and M. Balakrishnan},
  title = {Architecture Exploration of FPGA-Based Accelerators for Bioinformatics Applications},
  publisher = {Springer},
  address = {Singapore},
  year = {2016}
}
@misc{Lacey2016_DeepLearningFPGAs,
  author = {G. Lacey and G. W. Taylor and S. Areibi},
  title = {Deep Learning on FPGAs: Past, Present, and Future},
  howpublished = {arXiv preprint arXiv:1602.04283},
  year = {2016},
  url = {https://arxiv.org/abs/1602.04283}
}
@incollection{Farabet2011_FPGACNN,
  author = {C. Farabet and others},
  title = {Large-Scale FPGA-Based Convolutional Networks},
  booktitle = {Scaling up Machine Learning: Parallel and Distributed Approaches},
  editor = {R. Bekkerman and M. Bilenko and J. Langford},
  publisher = {Cambridge University Press},
  address = {Cambridge, U.K.},
  pages = {399--419},
  year = {2011}
}
@inproceedings{Munshi2009_OpenCLSpec,
  author = {A. Munshi},
  title = {The OpenCL Specification},
  booktitle = {Proceedings of the IEEE Hot Chips 21 Symposium (HCS)},
  pages = {13--14},
  year = {2009},
  month = {Aug.}
}
@article{Stone2010_OpenCLStandard,
  author = {J. E. Stone and D. Gohara and G. Shi},
  title = {OpenCL: A Parallel Programming Standard for Heterogeneous Computing Systems},
  journal = {Computer Science and Engineering},
  volume = {12},
  number = {3},
  pages = {66--73},
  year = {2010}
}
@book{Omondi2006_FPGA_NN,
  author = {A. R. Omondi and J. C. Rajapakse},
  title = {FPGA Implementations of Neural Networks},
  publisher = {Springer},
  address = {Boston, MA, USA},
  volume = {365},
  year = {2006}
}
@book{Waidyasooriya2018_OpenCLSystems,
  author = {H. M. Waidyasooriya and M. Hariyama and K. Uchiyama},
  title = {Design of FPGA-Based Computing Systems with OpenCL},
  publisher = {Springer},
  address = {Cham, Switzerland},
  year = {2018}
}
--------------------------------------------------------------------
@inproceedings{22Krizhevsky2012_ImageNet,
  author    = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle = {Proceedings of the International Conference on Neural Information Processing Systems (NIPS)},
  year      = {2012}
}
@article{3Amodei2015_DeepSpeech2,
  author    = {Dario Amodei and Rishita Anubhai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Jingdong Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Erich Elsen and Jesse Engel and Linxi Fan and Christopher Fougner and Tony Han and Awni Hannun and Billy Jun and Patrick LeGresley and Libby Lin and Sharan Narang and Andrew Ng and Sherjil Ozair and Ryan Prenger and Jonathan Raiman and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Yi Wang and Zhiqian Wang and Chong Wang and Bo Xiao and Dani Yogatama and Jun Zhan and Zhenyao Zhu},
  title     = {Deep Speech 2: End-To-End Speech Recognition in English and Mandarin},
  journal   = {arXiv preprint arXiv:1512.02595},
  year      = {2015},
  url       = {https://arxiv.org/abs/1512.02595}
}
@article{14Graves2005_LSTM,
  author    = {Alex Graves and J{\"u}rgen Schmidhuber},
  title     = {Framewise Phoneme Classification With Bidirectional LSTM and Other Neural Network Architectures},
  journal   = {Neural Networks},
  year      = {2005}
}
@article{18Hannun2014_DeepSpeech,
  author    = {Awni Hannun and Carl Case and Jared Casper and Bryan Catanzaro and Greg Diamos and Erich Elsen and Ryan Prenger and Sanjeev Satheesh and Shubho Sengupta and Adam Coates and Andrew Y. Ng},
  title     = {Deep Speech: Scaling Up End-To-End Speech Recognition},
  journal   = {arXiv preprint arXiv:1412.5567},
  year      = {2014},
  url       = {https://arxiv.org/abs/1412.5567}
}
@inproceedings{11Diamos2016_PersistentRNN,
  author    = {Gregory Diamos and Shubho Sengupta and Bryan Catanzaro and Mike Chrzanowski and Adam Coates and Erich Elsen and Jesse Engel and Awni Hannun and Sanjeev Satheesh},
  title     = {Persistent RNNs: Stashing Recurrent Weights On-Chip},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year      = {2016}
}
@article{23LeCun2015_DeepLearning,
  author    = {Yann LeCun and Yoshua Bengio and Geoffrey Hinton},
  title     = {Deep Learning},
  journal   = {Nature},
  volume    = {521},
  pages     = {436--444},
  year      = {2015}
}
@article{9Collobert2011_NLP,
  author    = {Ronan Collobert and Jason Weston and Leon Bottou and Michael Karlen and Koray Kavukcuoglu and Pavel Kuksa},
  title     = {Natural Language Processing (Almost) From Scratch},
  journal   = {arXiv preprint arXiv:1103.0398},
  year      = {2011},
  url       = {https://arxiv.org/abs/1103.0398}
}
----------------------------------------------------------------
A survey on FPGA-based accelerator for ML models
Why Use FPGA for Neural Networks?
@inproceedings{1Skourt2018_LungCTSegmentation,
  author    = {B. A. Skourt and A. El Hassani and A. Majda},
  title     = {Lung CT Image Segmentation Using Deep Neural Networks},
  booktitle = {Procedia Computer Science},
  year      = {2018},
  volume    = {127},
  pages     = {109--113}
}
@inproceedings{3He2016_ResNet,
  author    = {K. He and X. Zhang and S. Ren and J. Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {770--778}
}
@article{4Bochkovskiy2020_YOLOv4,
  author    = {A. Bochkovskiy and C.-Y. Wang and H.-Y. M. Liao},
  title     = {YOLOv4: Optimal Speed and Accuracy of Object Detection},
  journal   = {arXiv preprint arXiv:2004.10934},
  year      = {2020}
}
@inproceedings{5Saravanan2018_DataClassification,
  author    = {R. Saravanan and P. Sujatha},
  title     = {A State of Art Techniques on Machine Learning Algorithms: A Perspective of Supervised Learning Approaches in Data Classification},
  booktitle = {2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)},
  year      = {2018},
  pages     = {945--949},
  publisher = {IEEE}
}
@article{6Goldberg2020_NLPinPsychotherapy,
  author    = {S. B. Goldberg and N. Flemotomos and V. R. Martinez and M. J. Tanana and P. B. Kuo and B. T. Pace and J. L. Villatte and P. G. Georgiou and J. Van Epps and Z. E. Imel and others},
  title     = {Machine Learning and Natural Language Processing in Psychotherapy Research: Alliance as Example Use Case},
  journal   = {Journal of Counseling Psychology},
  year      = {2020},
  volume    = {67},
  number    = {4},
  pages     = {438}
}
@inproceedings{7Murshed2020_EdgeHazardDetection,
  author    = {M. S. Murshed and J. J. Carroll and N. Khan and F. Hussain},
  title     = {Resource-Aware On-Device Deep Learning for Supermarket Hazard Detection},
  booktitle = {2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  year      = {2020},
  pages     = {871--876},
  publisher = {IEEE}
}
@article{8Haghighat2021_SciANN,
  author    = {E. Haghighat and R. Juanes},
  title     = {SciANN: A Keras/TensorFlow Wrapper for Scientific Computations and Physics-Informed Deep Learning Using Artificial Neural Networks},
  journal   = {Computer Methods in Applied Mechanics and Engineering},
  year      = {2021},
  volume    = {373},
  pages     = {113552}
}
@inproceedings{9Settaluri2020_AutoCkt,
  author    = {K. Settaluri and A. Haj-Ali and Q. Huang and K. Hakhamaneshi and B. Nikolic},
  title     = {AutoCkt: Deep Reinforcement Learning of Analog Circuit Designs},
  booktitle = {2020 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  year      = {2020},
  pages     = {490--495},
  publisher = {IEEE}
}
@inproceedings{10Han2015_PruneEfficientNN,
  author    = {S. Han and J. Pool and J. Tran and W. Dally},
  title     = {Learning Both Weights and Connections for Efficient Neural Network},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2015},
  volume    = {28}
}

@inproceedings{ref15_Nakahara2018_YOLOv2,
  author    = {H. Nakahara and H. Yonekawa and T. Fujii and S. Sato},
  title     = {A lightweight YOLOv2: A binarized CNN with a parallel support vector regression for an FPGA},
  booktitle = {Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  year      = {2018},
  pages     = {31--40}
}
@inproceedings{ref24_Que2020_RNNAccelerator,
  author    = {Z. Que and H. Nakahara and H. Fan and J. Meng and K. H. Tsoi and X. Niu and E. Nurvitadhi and W. Luk},
  title     = {A reconfigurable multithreaded accelerator for recurrent neural networks},
  booktitle = {2020 International Conference on Field-Programmable Technology (ICFPT)},
  year      = {2020},
  pages     = {20--28}
}
@inproceedings{ref34_Rybalkin2020_2DLSTM,
  author    = {V. Rybalkin and N. Wehn},
  title     = {When massive GPU parallelism ain’t enough: A novel hardware architecture of 2D-LSTM neural network},
  booktitle = {FPGA 2020: ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  year      = {2020},
  pages     = {111--121}
}
@inproceedings{ref19_Gong2022_N3HCore,
  author    = {Y. Gong and Z. Xu and Z. He and W. Zhang and X. Tu and X. Liang and L. Jiang},
  title     = {N3H-Core: Neuron-designed neural network accelerator via FPGA-based heterogeneous computing cores},
  booktitle = {Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  year      = {2022},
  pages     = {112--122}
}
@inproceedings{ref50_Yingchang2023_M4BRAM,
  author    = {M. Yingchang and Q. Liu},
  title     = {M4BRAM: Mixed-precision matrix-matrix multiplication in FPGA block RAMs},
  booktitle = {2023 International Conference on Field Programmable Technology (ICFPT)},
  year      = {2023}
}
@inproceedings{ref57_Vestias2019_HybridDotProduct,
  author    = {M. P. Vé​stias and R. P. Duarte and J. T. de Sousa and H. Neto},
  title     = {Hybrid dot-product calculation for convolutional neural networks in FPGA},
  booktitle = {2019 29th International Conference on Field Programmable Logic and Applications (FPL)},
  year      = {2019},
  pages     = {350--353}
}
@inproceedings{ref58_Irmak2021_CNNFlexibility,
  author    = {H. Irmak and D. Ziener and N. Alachiotis},
  title     = {Increasing flexibility of FPGA-based CNN accelerators with dynamic partial reconfiguration},
  booktitle = {2021 31st International Conference on Field-Programmable Logic and Applications (FPL)},
  year      = {2021},
  pages     = {306--311}
}
@inproceedings{ref22_Colangelo2018_IntelFPGAs,
  author    = {P. Colangelo and N. Nasiri and E. Nurvitadhi and A. Mishra and M. Margala and K. Nealis},
  title     = {Exploration of low numeric precision deep learning inference using Intel FPGAs},
  booktitle = {2018 IEEE 26th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)},
  year      = {2018},
  pages     = {73--80}
}
@inproceedings{ref25_Ko2019_BayesianInference,
  author    = {G. G. Ko and Y. Chai and R. A. Rutenbar and D. Brooks and G.-Y. Wei},
  title     = {Accelerating Bayesian inference on structured graphs using parallel Gibbs sampling},
  booktitle = {2019 29th International Conference on Field Programmable Logic and Applications (FPL)},
  year      = {2019},
  pages     = {159--165}
}
@inproceedings{ref64_Sun2022_MicrostructuredCompression,
  author    = {M. Sun and S. Lin and S. Liu and S. Li and Y. Wang and W. Jiang and W. Wang},
  title     = {Hardware-friendly acceleration for deep neural networks with microstructured compression},
  booktitle = {2022 IEEE 30th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)},
  year      = {2022}
}
@inproceedings{ref65_Hall2020_TensorflowToLUTs,
  author    = {M. Hall and V. Betz},
  title     = {From TensorFlow graphs to LUTs and wires: Automated sparse and physically aware CNN hardware generation},
  booktitle = {2020 Int}
}
@inproceedings{36Diamantopoulos2018_TransprecisionFPGA,
  author = {Diamantopoulos, D. and Hagleitner, C.},
  title = {A system-level transprecision FPGA accelerator for BLSTM using on-chip memory reshaping},
  booktitle = {2018 International Conference on Field-Programmable Technology (FPT)},
  year = {2018},
  pages = {338--341},
  publisher = {IEEE}
}
@inproceedings{82Umuroglu2017_Finn,
  author = {Umuroglu, Y. and Fraser, N. and Gambardella, G. and Blott, M. and Leong, P. and Jahre, M. and Vissers, K.},
  title = {FINN: A Framework for Fast, Scalable Binarized Neural Network Inference},
  booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  year = {2017},
  pages = {65--74}
}
@inproceedings{83Zhou2019_EdgeDLInference,
  author = {Zhou, H. and Li, C. and Wang, Z. and Chen, X. and Qi, Y. and Cheng, B. and Song, L. and Cong, J.},
  title = {Enabling Low Latency Edge Inference of Deep Neural Networks on FPGAs},
  booktitle = {2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)},
  year = {2019},
  pages = {1--8},
  publisher = {IEEE}
}
----------------------------------------------------
for How FPGAs Accelerate Neural Networks
taken from FPGA-Based Accelerators of Deep Learning
 Networks for Learning and Classification:
 A Review
@inproceedings{Aydonat2017_DLA,
  author    = {U. Aydonat and S. O’Connell and D. Capalija and A. C. Ling and G. R. Chiu},
  title     = {An OpenCL Deep Learning Accelerator on Arria 10},
  booktitle = {Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays},
  year      = {2017},
  pages     = {55--64}
}
@inproceedings{Lu2017_Winograd,
  author    = {L. Lu et al.},
  title     = {Two-Dimensional Winograd Algorithm on FPGA},
  booktitle = {Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year      = {2017},
  pages     = {4013--4021}
}
@inproceedings{Venieris2017_fpgaConvNet,
  author    = {S. I. Venieris and C.-S. Bouganis},
  title     = {Latency-Driven Design for FPGA-Based Convolutional Neural Networks},
  booktitle = {Proc. 27th Int. Conf. Field Program. Logic Appl. (FPL)},
  year      = {2017},
  pages     = {1--8}
}
@inproceedings{Yuan2017_FP_DNN,
  author    = {Y. Guan et al.},
  title     = {FP-DNN: An Automated Framework for Mapping Deep Neural Networks onto FPGAs},
  booktitle = {Proc. IEEE 25th Annu. Int. Symp. Field-Program. Custom Comput. Mach. (FCCM)},
  year      = {2017},
  pages     = {152--159}
}
@article{Zhang2017_Roofline,
  author    = {C. Zhang and V. Prasanna},
  title     = {Frequency Domain Acceleration of Convolutional Neural Networks on CPU–FPGA Systems},
  journal   = {Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays},
  year      = {2017},
  pages     = {35--44}
}

@inproceedings{ref83_Ma2017_OptimizingLoop,
  author    = {Y. Ma, Y. Cao, S. Vrudhula, and J.-S. Seo},
  title     = {Optimizing Loop Operation and Dataflow in FPGA Acceleration of Deep Convolutional Neural Networks},
  booktitle = {Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays (FPGA)},
  year      = {2017},
  pages     = {45--54}
}
@inproceedings{ref80_Suda2016_OpenCLAccelerator,
  author    = {N. Suda and V. Chandra and G. Dasika and A. Mohanty and Y. Ma and S. Vrudhula and J.-S. Seo and Y. Cao},
  title     = {Throughput-Optimized OpenCL-Based FPGA Accelerator for Large-Scale Convolutional Neural Networks},
  booktitle = {Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays (FPGA)},
  year      = {2016},
  pages     = {16--25}
}
@inproceedings{ref98_Qiu2016_GoingDeeper,
  author    = {J. Qiu and J. Wang and S. Yao and K. Guo and B. Li and E. Zhou and J. Yu and T. Tang and N. Xu and S. Song and Y. Wang and H. Yang},
  title     = {Going Deeper with Embedded FPGA Platform for Convolutional Neural Network},
  booktitle = {Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays (FPGA)},
  year      = {2016},
  pages     = {26--35}
}
@inproceedings{ref189_Lu2017_FastAlgorithms,
  author    = "L. Lu and Y. Liang and Q. Xiao and S. Yan",
  title     = "Evaluating Fast Algorithms for Convolutional Neural Networks on FPGAs",
  booktitle = "Proceedings of the IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)",
  year      = "2017",
  pages     = "101--108"
}
@inproceedings{Chen2014_DianNao,
  author    = {T. Chen and others},
  title     = {DianNao: A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning},
  booktitle = {ACM SIGPLAN Notices},
  volume    = {49},
  number    = {4},
  pages     = {269--284},
  year      = {2014}
}
@inproceedings{Ref97_Sze2017_Hardware_ML,
  author    = {V. Sze and Y.-H. Chen and J. Emer and A. Suleiman and Z. Zhang},
  title     = {Hardware for Machine Learning: Challenges and Opportunities},
  booktitle = {Proc. IEEE Custom Integrated Circuits Conf. (CICC)},
  year      = {2017},
  pages     = {1--8},
  month     = {Apr./May}
}
@inproceedings{Lu2017_FlexFlow,
  author    = {W. Lu and G. Yan and J. Li and S. Gong and Y. Han and X. Li},
  title     = {FlexFlow: A Flexible Dataflow Accelerator Architecture for Convolutional Neural Networks},
  booktitle = {Proc. IEEE Int. Symp. High Perform. Comput. Archit. (HPCA)},
  pages     = {553--564},
  year      = {2017},
  month     = feb
}
@inproceedings{Ref58_Jia2014_Caffe,
  author    = {Y. Jia and others},
  title     = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  booktitle = {Proceedings of the 22nd ACM International Conference on Multimedia},
  pages     = {675--678},
  year      = {2014}
}
@article{Ref72_Hameed2010_InefficiencyChips,
  author    = {R. Hameed and W. Qadeer and M. Wachs and O. Azizi and A. Solomatnikov and B. C. Lee and S. Richardson and C. Kozyrakis and M. Horowitz},
  title     = {Understanding Sources of Inefficiency in General-Purpose Chips},
  journal   = {ACM SIGARCH Computer Architecture News},
  volume    = {38},
  number    = {3},
  pages     = {37--47},
  year      = {2010},
  month     = jun
}

